{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports & Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, TypeVar, Type\n",
    "\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from langchain.schema.messages import BaseMessage\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.adapters.openai import convert_message_to_dict\n",
    "\n",
    "T = TypeVar('T', bound=BaseModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create an instructor integrated `runnable`\n",
    "\n",
    "> Supports OpenAI compatible API. [Ollama, vLLM, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instructor_runnable(\n",
    "    mode: instructor.Mode,\n",
    "    model: str,\n",
    "    response_model: Type[T],\n",
    "    base_url: Optional[str] = None,\n",
    "    api_key: Optional[str] = None,\n",
    "    **kwargs\n",
    ") -> RunnableLambda[str | list[BaseMessage], T]: \n",
    "    \"\"\"\n",
    "    Create an instructor integrated langchain runnable.\n",
    "    @param mode: instructor mode to use.\n",
    "    @param model: Model to use.\n",
    "    @param response_model: pydantic class to format output.\n",
    "    @param base_url: Base URL to get chat completions.\n",
    "    @param api_key: API key to use for requesting base URL.\n",
    "    @param kwargs: Extra kwargs to pass to create method.\n",
    "    \"\"\"\n",
    "    \n",
    "    client = instructor.patch(\n",
    "        OpenAI(base_url=base_url, api_key=api_key), mode=mode)\n",
    "    aclient = instructor.patch(\n",
    "        AsyncOpenAI(base_url=base_url, api_key=api_key), mode=mode)\n",
    "    \n",
    "    load_kwargs = (\n",
    "        lambda x: {\n",
    "            'messages':([{'role': 'user', 'content': x}] \n",
    "                if isinstance(x, str) \n",
    "                else [convert_message_to_dict(msg) for msg in x]),\n",
    "            'model': model,\n",
    "            'response_model': response_model,\n",
    "        } | kwargs \n",
    "    )\n",
    "\n",
    "    def func(__arg):\n",
    "        return client.chat.completions.create(**load_kwargs(__arg))\n",
    "    \n",
    "    async def afunc(__arg):\n",
    "        return await aclient.chat.completions.create(**load_kwargs(__arg))\n",
    "\n",
    "    return RunnableLambda(func=func, afunc=afunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "- Create a Response Model that represents how the final output should be.\n",
    "- Create a instructor runnable \n",
    "- Invoke the runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    fact: str = Field(..., description=\"A fact about the character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = create_instructor_runnable(\n",
    "    mode=instructor.Mode.JSON,\n",
    "    model='llama2', \n",
    "    response_model=Character, \n",
    "    base_url=\"http://localhost:11434/v1\", # Ollama default URL\n",
    "    api_key=\"ollama\" # not required, you can leave it empty\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Character(name='Elon Musk', age=49, fact='He is the CEO of SpaceX and Tesla, Inc.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('Tell me about Elon Musk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Character(name='Ichigo Kurosaki', age=15, fact='He has the ability to turn into a Shinigami, a death god, and can use his Zanpakuto to fight against evil forces.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.messages import SystemMessage, HumanMessage\n",
    "\n",
    "await llm.ainvoke([\n",
    "    SystemMessage(content='Answer query related to anime \"Bleach\"'),\n",
    "    HumanMessage(content='Who is Ichigo Kurosaki.')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
