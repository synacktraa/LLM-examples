{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports & Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, TypeVar, Type\n",
    "\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from langchain.schema.messages import BaseMessage\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.adapters.openai import convert_message_to_dict\n",
    "\n",
    "T = TypeVar('T', bound=BaseModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create an instructor integrated `runnable`\n",
    "\n",
    "> Supports OpenAI compatible API. [Ollama, vLLM, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_messages_map(__prompt_or_messages: str | list[BaseMessage]) -> list[dict[str, str]]:\n",
    "    \"\"\"Build OpenAI API compatible messages.\"\"\"\n",
    "    if isinstance(__prompt_or_messages, str):\n",
    "        messages = [{'role': 'user', 'content': __prompt_or_messages}]\n",
    "    else:\n",
    "        messages = [convert_message_to_dict(msg) for msg in __prompt_or_messages]\n",
    "\n",
    "    return {'messages': messages}\n",
    "\n",
    "def create_instructor_runnable(\n",
    "    model: str,\n",
    "    response_model: Type[T],\n",
    "    base_url: Optional[str] = None,\n",
    "    api_key: Optional[str] = None,\n",
    "    mode: Optional[instructor.Mode] = None,\n",
    "    **kwargs\n",
    ") -> RunnableLambda[str | list[BaseMessage], T]: \n",
    "    \"\"\"\n",
    "    Create an instructor integrated langchain runnable.\n",
    "    @param model: Model to use.\n",
    "    @param response_model: pydantic class to format output.\n",
    "    @param base_url: Base URL to get chat completions.\n",
    "    @param api_key: API key to use for requesting base URL.\n",
    "    @param mode: instructor mode to use. [default: JSON]\n",
    "    @param kwargs: Extra kwargs to pass to create method.\n",
    "    \"\"\"\n",
    "    mode = mode or instructor.Mode.JSON\n",
    "    client = instructor.patch(\n",
    "        OpenAI(base_url=base_url, api_key=api_key), mode=mode)\n",
    "    aclient = instructor.patch(\n",
    "        AsyncOpenAI(base_url=base_url, api_key=api_key), mode=mode)\n",
    "\n",
    "    load_kwargs = (\n",
    "        lambda x: build_messages_map(x) \n",
    "        | kwargs \n",
    "        | {'model': model, 'response_model': response_model}\n",
    "    )\n",
    "\n",
    "    def func(__arg):\n",
    "        return client.chat.completions.create(**load_kwargs(__arg))\n",
    "    \n",
    "    async def afunc(__arg):\n",
    "        return await aclient.chat.completions.create(**load_kwargs(__arg))\n",
    "\n",
    "    return RunnableLambda(func=func, afunc=afunc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "- Create a Response Model that represents how the final output should be.\n",
    "- Create a instructor runnable \n",
    "- Invoke the runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    fact: str = Field(..., description=\"A fact about the character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = create_instructor_runnable(\n",
    "    model='llama2', \n",
    "    response_model=Character, \n",
    "    base_url=\"http://localhost:11434/v1\", # Ollama default URL\n",
    "    api_key=\"ollama\" # not required, you can leave it empty\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Character(name='Elon Musk', age=49, fact='He is a billionaire entrepreneur and inventor known for his innovative ideas and technological advancements in the fields of electric cars, space exploration, and renewable energy.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('Tell me about Elon Musk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Character(name='Ichigo Kurosaki', age=150, fact='He can transform into a Shinigami and play the drum.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.messages import HumanMessage\n",
    "await llm.ainvoke([HumanMessage(content='Who is Ichigo Kurosaki.')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
